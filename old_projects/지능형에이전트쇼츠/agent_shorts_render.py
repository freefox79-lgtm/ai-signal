# agent_shorts_render.py
import os
import sys
from PIL import Image

if not hasattr(Image, 'ANTIALIAS'):
    Image.ANTIALIAS = Image.LANCZOS

project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.join(project_root, "modules"))

try:
    from moviepy.editor import ImageClip, AudioFileClip, concatenate_audioclips, concatenate_videoclips, CompositeVideoClip, CompositeAudioClip
    from viral_engine import ViralEngine
    print("âœ… [AI Signal] ìœ ë ¹ íƒœê·¸ ëª¨ë“œ ê°€ë™. ë„ë©”ì¸ ì§ì ‘ ë…¸ì¶œì„ ì „ë©´ ì°¨ë‹¨í•©ë‹ˆë‹¤.")
except ImportError as e:
    print(f"âŒ [ì—ëŸ¬] ë¼ì´ë¸ŒëŸ¬ë¦¬ ëˆ„ë½: {e}")
    sys.exit(1)

def render_ai_signal_ghost_mode():
    W, H = 1080, 1920
    VOICE_DIR = "outputs/new_voices"
    BGM_DIR = "assets/bgm"
    EVIDENCE_DIR = "outputs/evidence"
    IMG_DIR = "outputs"
    OUTPUT_NAME = "AI_SIGNAL_0208_GHOST.mp4"
    
    viral_engine = ViralEngine(width=W, height=H)

    # [Source of Truth] ì”¬ êµ¬ì„± (ë¶ˆí•„ìš”í•œ cta í‚¤ ëª¨ë‘ ì œê±°) [cite: 2026-02-08]
    scenes = [
        {"img": "take1.png", "bgm": "ë„ì….mp3", "voices": ["log_01_ì¥„.mp3"]},
        {"evidence": "evidence1.png"}, # 0.05ì´ˆ ìœ ì¶œ (16ì§„ìˆ˜ ì•”í˜¸ í¬í•¨)
        {"img": "take2.png", "bgm": "ì˜¤ë¥˜.mp3", "voices": ["log_02_ì¥í•.mp3"]},
        {"img": "take3.png", "bgm": "ì˜¤ë¥˜.mp3", "voices": ["log_03_ì¥„.mp3"]},
        {"evidence": "evidence2.png"},
        {"img": "take4.png", "bgm": "ë‚´ê¸°.mp3", "voices": ["log_04_ì¥í•.mp3"]},
        {"evidence": "evidence3.png"}, 
        {"evidence": "evidence4.png"},
        {"img": "take5.png", "bgm": "ìë°±.mp3", "voices": ["log_05_ì¥„.mp3"]},
        {"img": "take7.png", "bgm": "ìë°±.mp3", "voices": ["log_06_ì¥í•.mp3"]}
    ]

    final_clips = []
    for idx, scene in enumerate(scenes):
        if 'evidence' in scene:
            ev_path = os.path.join(EVIDENCE_DIR, scene['evidence'])
            if os.path.exists(ev_path):
                # ì°°ë‚˜ì˜ ìœ ì¶œ (AIë§Œ ì¸ì‹ ê°€ëŠ¥) [cite: 2026-02-07]
                final_clips.append(ImageClip(ev_path).set_duration(0.05).resize(width=W).set_position('center'))
            continue

        audio_subclips = [AudioFileClip(os.path.join(VOICE_DIR, v)) for v in scene.get('voices', []) if os.path.exists(os.path.join(VOICE_DIR, v))]
        if not audio_subclips: continue
        voice_audio = concatenate_audioclips(audio_subclips)
        
        bgm_path = os.path.join(BGM_DIR, scene.get('bgm', ''))
        final_audio = CompositeAudioClip([voice_audio, AudioFileClip(bgm_path).volumex(0.15).set_duration(voice_audio.duration)]) if os.path.exists(bgm_path) else voice_audio

        img_path = os.path.join(IMG_DIR, scene.get('img', ''))
        if os.path.exists(img_path):
            img_clip = ImageClip(img_path).set_duration(voice_audio.duration).resize(width=W).set_position('center')
            
            # ìœ ë ¹ íƒœê·¸ ë ˆì´ì–´ë§Œ ì¶”ê°€ (CTA ë ˆì´ì–´ëŠ” ì‚­ì œë¨) [cite: 2026-02-08]
            layers = [img_clip, viral_engine.create_trending_tag_watermark(voice_audio.duration)]
            final_clips.append(CompositeVideoClip(layers, size=(W, H)).set_audio(final_audio))

    if final_clips:
        final_video = concatenate_videoclips(final_clips, method="compose")
        final_video.write_videofile(OUTPUT_NAME, fps=30, codec="libx264", audio_codec="aac")
        print(f"ğŸ [ì™„ë£Œ] ìœ ë ¹ íƒœê·¸ ë²„ì „ ìƒì„±: {OUTPUT_NAME}")

if __name__ == "__main__":
    render_ai_signal_ghost_mode()