"""
AI Signal í™•ì¥ì„± ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ

ì‚¬ìš©ì ìˆ˜, ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ì„ ëª¨ë‹ˆí„°ë§í•˜ê³ 
ì¸í”„ë¼ í™•ì¥ì´ í•„ìš”í•œ ì‹œì ì— ì•Œë¦¼ ë° ì œì•ˆ ì œê³µ
"""

import os
import psutil
import redis
from datetime import datetime, timedelta
from typing import Dict, List, Optional
from dataclasses import dataclass
from dotenv import load_dotenv
from db_utils import get_db_connection

load_dotenv(".env.local")


@dataclass
class ScalingThreshold:
    """í™•ì¥ ì„ê³„ê°’"""
    users: int
    cpu_percent: float
    memory_percent: float
    redis_memory_mb: float
    db_size_mb: float
    bandwidth_gb: float


@dataclass
class ScalingRecommendation:
    """í™•ì¥ ì œì•ˆ"""
    level: str  # "warning", "critical", "urgent"
    title: str
    description: str
    actions: List[str]
    estimated_cost: str
    timeline: str


class ScalingMonitor:
    """í™•ì¥ì„± ëª¨ë‹ˆí„°ë§"""
    
    # í™•ì¥ ë‹¨ê³„ë³„ ì„ê³„ê°’
    THRESHOLDS = {
        "beta": ScalingThreshold(
            users=100,
            cpu_percent=70,
            memory_percent=70,
            redis_memory_mb=100,
            db_size_mb=400,
            bandwidth_gb=4
        ),
        "growth": ScalingThreshold(
            users=1000,
            cpu_percent=80,
            memory_percent=80,
            redis_memory_mb=500,
            db_size_mb=7000,
            bandwidth_gb=40
        ),
        "scale": ScalingThreshold(
            users=10000,
            cpu_percent=85,
            memory_percent=85,
            redis_memory_mb=2000,
            db_size_mb=50000,
            bandwidth_gb=400
        )
    }
    
    def __init__(self):
        self.redis_client = self._init_redis()
        self.current_stage = self._detect_current_stage()
    
    def _init_redis(self) -> Optional[redis.Redis]:
        """Redis ì—°ê²°"""
        try:
            r = redis.Redis(
                host='localhost',
                port=6379,
                password=os.getenv("REDIS_PASSWORD", "aisignal2026_secure"),
                decode_responses=True
            )
            r.ping()
            return r
        except Exception as e:
            print(f"[ScalingMonitor] Redis ì—°ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def _detect_current_stage(self) -> str:
        """í˜„ì¬ ë‹¨ê³„ ê°ì§€"""
        users = self.get_user_count()
        
        if users < 100:
            return "development"
        elif users < 1000:
            return "beta"
        elif users < 10000:
            return "growth"
        else:
            return "scale"
    
    def get_user_count(self) -> int:
        """ì‚¬ìš©ì ìˆ˜ ì¡°íšŒ (Supabase)"""
        try:
            conn = get_db_connection(routing='cloud')
            with conn.cursor() as cur:
                cur.execute("SELECT COUNT(*) FROM users")
                count = cur.fetchone()[0]
            return count
        except Exception as e:
            print(f"[ScalingMonitor] ì‚¬ìš©ì ìˆ˜ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return 0
    
    def get_system_metrics(self) -> Dict:
        """ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        # ê¸°ë³¸ ì‹œìŠ¤í…œ ì •ë³´
        vm = psutil.virtual_memory()
        disk = psutil.disk_usage('/')
        
        metrics = {
            "timestamp": datetime.now().isoformat(),
            "users": self.get_user_count(),
            "cpu_percent": psutil.cpu_percent(interval=1),
            "cpu_count": psutil.cpu_count(),
            "memory_percent": vm.percent,
            "memory_total_gb": vm.total / (1024**3),
            "memory_used_gb": vm.used / (1024**3),
            "disk_percent": disk.percent,
            "disk_total_gb": disk.total / (1024**3),
            "disk_used_gb": disk.used / (1024**3),
        }
        
        # CPU ì˜¨ë„ (Mac Mini)
        try:
            temps = psutil.sensors_temperatures()
            if temps:
                # Macì˜ ê²½ìš° 'coretemp' ë˜ëŠ” 'cpu_thermal' ì‚¬ìš©
                for name, entries in temps.items():
                    if entries:
                        metrics["cpu_temp"] = entries[0].current
                        break
        except:
            metrics["cpu_temp"] = None
        
        # Redis ë©”ëª¨ë¦¬
        if self.redis_client:
            try:
                info = self.redis_client.info("memory")
                metrics["redis_memory_mb"] = info["used_memory"] / (1024 * 1024)
            except:
                metrics["redis_memory_mb"] = 0
        
        return metrics
    
    def check_scaling_needs(self) -> List[ScalingRecommendation]:
        """í™•ì¥ í•„ìš”ì„± ì²´í¬"""
        metrics = self.get_system_metrics()
        recommendations = []
        
        # ì‚¬ìš©ì ìˆ˜ ê¸°ë°˜ ì²´í¬
        users = metrics["users"]
        
        if users >= 100 and self.current_stage == "development":
            recommendations.append(ScalingRecommendation(
                level="warning",
                title="ë² íƒ€ ë‹¨ê³„ ì „í™˜ ê¶Œì¥",
                description=f"ì‚¬ìš©ì {users}ëª… ë„ë‹¬. Render ë°°í¬ ê³ ë ¤ í•„ìš”.",
                actions=[
                    "Render.comì— ë°°í¬ (1 instance)",
                    "Supabase Free í”Œëœ ìœ ì§€",
                    "Ollama â†’ OpenAI API ì „í™˜ ê³ ë ¤",
                    "ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì¶”ê°€ (Sentry)"
                ],
                estimated_cost="$21/ì›”",
                timeline="1ì£¼ì¼ ë‚´"
            ))
        
        if users >= 1000 and self.current_stage == "beta":
            recommendations.append(ScalingRecommendation(
                level="critical",
                title="ì„±ì¥ ë‹¨ê³„ ì „í™˜ í•„ìš”",
                description=f"ì‚¬ìš©ì {users}ëª… ë„ë‹¬. ì¸í”„ë¼ í™•ì¥ í•„ìš”.",
                actions=[
                    "Render ì¸ìŠ¤í„´ìŠ¤ 2ê°œë¡œ ì¦ì„¤",
                    "Supabase Pro í”Œëœ ì—…ê·¸ë ˆì´ë“œ ($25/ì›”)",
                    "Redis Cloud ì¶”ê°€ ($10/ì›”)",
                    "CDN ì„¤ì • (Cloudflare)",
                    "ë¡œë“œ ë°¸ëŸ°ì‹± êµ¬ì„±"
                ],
                estimated_cost="$67/ì›”",
                timeline="3ì¼ ë‚´"
            ))
        
        if users >= 10000 and self.current_stage == "growth":
            recommendations.append(ScalingRecommendation(
                level="urgent",
                title="ìŠ¤ì¼€ì¼ ë‹¨ê³„ ì „í™˜ ê¸´ê¸‰",
                description=f"ì‚¬ìš©ì {users}ëª… ë„ë‹¬. ì¦‰ì‹œ í™•ì¥ í•„ìš”.",
                actions=[
                    "Render ì¸ìŠ¤í„´ìŠ¤ 3ê°œ ì´ìƒìœ¼ë¡œ ì¦ì„¤",
                    "Database Read Replicas ì¶”ê°€",
                    "Redis Cluster êµ¬ì„±",
                    "Auto-scaling ì„¤ì •",
                    "ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê°•í™” (DataDog)"
                ],
                estimated_cost="$148/ì›”",
                timeline="ì¦‰ì‹œ"
            ))
        
        # CPU ì‚¬ìš©ë¥  ì²´í¬
        if metrics["cpu_percent"] > 85:
            recommendations.append(ScalingRecommendation(
                level="critical",
                title="CPU ì‚¬ìš©ë¥  ì„ê³„ì¹˜ ì´ˆê³¼",
                description=f"CPU ì‚¬ìš©ë¥  {metrics['cpu_percent']:.1f}% (ì„ê³„ì¹˜: 85%)",
                actions=[
                    "ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ ì¶”ê°€",
                    "ë¡œë“œ ë°¸ëŸ°ì‹± êµ¬ì„±",
                    "ì½”ë“œ ìµœì í™” ê²€í† "
                ],
                estimated_cost="ì¸ìŠ¤í„´ìŠ¤ë‹¹ $21/ì›”",
                timeline="24ì‹œê°„ ë‚´"
            ))
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì²´í¬
        if metrics["memory_percent"] > 85:
            recommendations.append(ScalingRecommendation(
                level="critical",
                title="ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì„ê³„ì¹˜ ì´ˆê³¼",
                description=f"ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  {metrics['memory_percent']:.1f}% (ì„ê³„ì¹˜: 85%)",
                actions=[
                    "ë©”ëª¨ë¦¬ ì¦ì„¤ ë˜ëŠ” ì¸ìŠ¤í„´ìŠ¤ ì—…ê·¸ë ˆì´ë“œ",
                    "ìºì‹± ì „ëµ ìµœì í™”",
                    "ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ì ê²€"
                ],
                estimated_cost="$10-30/ì›” ì¶”ê°€",
                timeline="24ì‹œê°„ ë‚´"
            ))
        
        # Mac Mini í•˜ë“œì›¨ì–´ í•œê³„ ì²´í¬
        hw_recommendations = self._check_hardware_limits(metrics)
        recommendations.extend(hw_recommendations)
        
        return recommendations
    
    def _check_hardware_limits(self, metrics: Dict) -> List[ScalingRecommendation]:
        """Mac Mini í•˜ë“œì›¨ì–´ í•œê³„ ì²´í¬ ë° ì—…ê·¸ë ˆì´ë“œ ì œì•ˆ"""
        recommendations = []
        
        # Mac Mini ì‚¬ì–‘ (ì˜ˆ: M2, 8GB RAM, 256GB SSD)
        # ì‹¤ì œ ì‚¬ì–‘ì€ ìë™ ê°ì§€ëœ ê°’ ì‚¬ìš©
        total_ram_gb = metrics.get("memory_total_gb", 8)
        total_disk_gb = metrics.get("disk_total_gb", 256)
        cpu_count = metrics.get("cpu_count", 8)
        
        # 1. RAM í•œê³„ ì²´í¬ (8GB Mac Mini)
        if total_ram_gb <= 8 and metrics["memory_percent"] > 75:
            recommendations.append(ScalingRecommendation(
                level="warning",
                title="ğŸ–¥ï¸ Mac Mini RAM ìš©ëŸ‰ ë¶€ì¡±",
                description=f"í˜„ì¬ RAM: {total_ram_gb:.0f}GB, ì‚¬ìš©ë¥ : {metrics['memory_percent']:.1f}%\n8GB RAMì€ ê°œë°œ í™˜ê²½ì—ë§Œ ì í•©í•©ë‹ˆë‹¤.",
                actions=[
                    "Mac Mini 16GB ë˜ëŠ” 24GB ëª¨ë¸ë¡œ ì—…ê·¸ë ˆì´ë“œ",
                    "ë˜ëŠ” Render.com í´ë¼ìš°ë“œë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜",
                    "ë©”ëª¨ë¦¬ ì§‘ì•½ì  ì‘ì—… ìµœì í™” (Ollama ëª¨ë¸ ê²½ëŸ‰í™”)",
                    "Redis ë©”ëª¨ë¦¬ ì œí•œ ì„¤ì •"
                ],
                estimated_cost="Mac Mini 16GB: $799 / Render: $21/ì›”",
                timeline="ì‚¬ìš©ì 50ëª… ë„ë‹¬ ì „"
            ))
        
        # 2. ë””ìŠ¤í¬ ìš©ëŸ‰ ì²´í¬ (256GB SSD)
        if total_disk_gb <= 256 and metrics["disk_percent"] > 70:
            recommendations.append(ScalingRecommendation(
                level="warning",
                title="ğŸ’¾ Mac Mini ë””ìŠ¤í¬ ìš©ëŸ‰ ë¶€ì¡±",
                description=f"í˜„ì¬ ë””ìŠ¤í¬: {total_disk_gb:.0f}GB, ì‚¬ìš©ë¥ : {metrics['disk_percent']:.1f}%\në¡œê·¸, ìºì‹œ, ëª¨ë¸ íŒŒì¼ë¡œ ë¹ ë¥´ê²Œ ì†Œì§„ë©ë‹ˆë‹¤.",
                actions=[
                    "Mac Mini 512GB ì´ìƒ ëª¨ë¸ë¡œ ì—…ê·¸ë ˆì´ë“œ",
                    "ì™¸ì¥ SSD ì¶”ê°€ (Thunderbolt)",
                    "ë¡œê·¸ ë¡œí…Œì´ì…˜ ì„¤ì •",
                    "Ollama ëª¨ë¸ì„ ì™¸ì¥ ë””ìŠ¤í¬ë¡œ ì´ë™",
                    "í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ í™œìš© (S3, Supabase Storage)"
                ],
                estimated_cost="512GB ëª¨ë¸: $999 / ì™¸ì¥ SSD: $100-200",
                timeline="ë””ìŠ¤í¬ 80% ë„ë‹¬ ì „"
            ))
        
        # 3. CPU ì˜¨ë„ ì²´í¬ (ê³¼ì—´ ê²½ê³ )
        cpu_temp = metrics.get("cpu_temp")
        if cpu_temp and cpu_temp > 80:
            recommendations.append(ScalingRecommendation(
                level="critical",
                title="ğŸŒ¡ï¸ Mac Mini CPU ê³¼ì—´ ê²½ê³ ",
                description=f"CPU ì˜¨ë„: {cpu_temp:.1f}Â°C (ì •ìƒ: 60-70Â°C)\nì§€ì†ì ì¸ ê³ ë¶€í•˜ë¡œ ì¸í•œ ê³¼ì—´ ìœ„í—˜.",
                actions=[
                    "Mac Mini ì¿¨ë§ íŒ¨ë“œ ì‚¬ìš©",
                    "í†µí’ì´ ì˜ ë˜ëŠ” ê³³ìœ¼ë¡œ ì´ë™",
                    "CPU ì§‘ì•½ì  ì‘ì—…ì„ í´ë¼ìš°ë“œë¡œ ì˜¤í”„ë¡œë“œ",
                    "Ollama ì¶”ë¡ ì„ GPU ì„œë²„ë¡œ ì´ì „ (Render + GPU)",
                    "ë°±ê·¸ë¼ìš´ë“œ í”„ë¡œì„¸ìŠ¤ ìµœì í™”"
                ],
                estimated_cost="ì¿¨ë§ íŒ¨ë“œ: $30 / GPU ì„œë²„: $50/ì›”",
                timeline="ì¦‰ì‹œ"
            ))
        
        # 4. ì¢…í•© ì—…ê·¸ë ˆì´ë“œ ì œì•ˆ (ì‚¬ìš©ì 100ëª… ì´ìƒ)
        if metrics["users"] >= 100 and (total_ram_gb <= 8 or total_disk_gb <= 256):
            recommendations.append(ScalingRecommendation(
                level="urgent",
                title="ğŸš€ Mac Mini í•œê³„ ë„ë‹¬ - í´ë¼ìš°ë“œ ë§ˆì´ê·¸ë ˆì´ì…˜ ê¶Œì¥",
                description=f"ì‚¬ìš©ì {metrics['users']}ëª… ë„ë‹¬. Mac MiniëŠ” ê°œë°œ/í…ŒìŠ¤íŠ¸ í™˜ê²½ì— ì í•©í•˜ë©°, í”„ë¡œë•ì…˜ í™˜ê²½ìœ¼ë¡œëŠ” ë¶€ì í•©í•©ë‹ˆë‹¤.",
                actions=[
                    "Render.comìœ¼ë¡œ ì™„ì „ ë§ˆì´ê·¸ë ˆì´ì…˜ (ê¶Œì¥)",
                    "ë˜ëŠ” Mac Mini M2 Pro (16GB+ RAM, 512GB+ SSD) ì—…ê·¸ë ˆì´ë“œ",
                    "í•˜ì´ë¸Œë¦¬ë“œ: Mac Mini (ê°œë°œ) + Render (í”„ë¡œë•ì…˜)",
                    "ë¡œë“œ ë°¸ëŸ°ì‹±: Mac Mini + í´ë¼ìš°ë“œ ì¸ìŠ¤í„´ìŠ¤",
                    "ëª¨ë‹ˆí„°ë§ ê°•í™”: Uptime, ì„±ëŠ¥ ì¶”ì "
                ],
                estimated_cost="Render ë§ˆì´ê·¸ë ˆì´ì…˜: $21/ì›” / Mac Mini M2 Pro: $1,299",
                timeline="1ì£¼ì¼ ë‚´"
            ))
        
        # 5. ë””ìŠ¤í¬ I/O ë³‘ëª© ì²´í¬
        if metrics["disk_percent"] > 85:
            recommendations.append(ScalingRecommendation(
                level="critical",
                title="âš ï¸ ë””ìŠ¤í¬ ìš©ëŸ‰ ì„ê³„ì¹˜ ì´ˆê³¼",
                description=f"ë””ìŠ¤í¬ ì‚¬ìš©ë¥ : {metrics['disk_percent']:.1f}%\nì‹œìŠ¤í…œ ë¶ˆì•ˆì • ìœ„í—˜.",
                actions=[
                    "ì¦‰ì‹œ ë¶ˆí•„ìš”í•œ íŒŒì¼ ì‚­ì œ",
                    "ë¡œê·¸ íŒŒì¼ ì •ë¦¬ (Docker, n8n, Streamlit)",
                    "Ollama ëª¨ë¸ ìºì‹œ ì •ë¦¬",
                    "ì™¸ì¥ SSDë¡œ ë°ì´í„° ì´ë™",
                    "í´ë¼ìš°ë“œ ë§ˆì´ê·¸ë ˆì´ì…˜ ê³ ë ¤"
                ],
                estimated_cost="ì™¸ì¥ SSD: $100-200",
                timeline="24ì‹œê°„ ë‚´"
            ))
        
        return recommendations
    
    def save_metrics_history(self):
        """ë©”íŠ¸ë¦­ íˆìŠ¤í† ë¦¬ ì €ì¥ (Redis)"""
        if not self.redis_client:
            return
        
        metrics = self.get_system_metrics()
        key = f"metrics:{datetime.now().strftime('%Y%m%d%H')}"
        
        try:
            self.redis_client.setex(
                key,
                86400 * 7,  # 7ì¼ ë³´ê´€
                str(metrics)
            )
        except Exception as e:
            print(f"[ScalingMonitor] ë©”íŠ¸ë¦­ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def generate_report(self) -> str:
        """í™•ì¥ì„± ë³´ê³ ì„œ ìƒì„±"""
        metrics = self.get_system_metrics()
        recommendations = self.check_scaling_needs()
        
        report = f"""
# AI Signal í™•ì¥ì„± ë³´ê³ ì„œ
**ìƒì„± ì‹œê°„**: {metrics['timestamp']}
**í˜„ì¬ ë‹¨ê³„**: {self.current_stage.upper()}

## ğŸ“Š í˜„ì¬ ë©”íŠ¸ë¦­

### ë¹„ì¦ˆë‹ˆìŠ¤ ë©”íŠ¸ë¦­
- **ì‚¬ìš©ì ìˆ˜**: {metrics['users']:,}ëª…

### ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤
- **CPU ì‚¬ìš©ë¥ **: {metrics['cpu_percent']:.1f}% (ì½”ì–´: {metrics.get('cpu_count', 'N/A')}ê°œ)
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ **: {metrics['memory_percent']:.1f}% ({metrics.get('memory_used_gb', 0):.1f}GB / {metrics.get('memory_total_gb', 0):.1f}GB)
- **ë””ìŠ¤í¬ ì‚¬ìš©ë¥ **: {metrics['disk_percent']:.1f}% ({metrics.get('disk_used_gb', 0):.1f}GB / {metrics.get('disk_total_gb', 0):.1f}GB)
- **Redis ë©”ëª¨ë¦¬**: {metrics.get('redis_memory_mb', 0):.1f} MB
"""
        
        if not recommendations:
            report += "\nâœ… í˜„ì¬ ì¸í”„ë¼ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤.\n"
        else:
            for i, rec in enumerate(recommendations, 1):
                level_emoji = {
                    "warning": "âš ï¸",
                    "critical": "ğŸ”´",
                    "urgent": "ğŸš¨"
                }
                
                report += f"""
### {level_emoji[rec.level]} {rec.title}
**ì‹¬ê°ë„**: {rec.level.upper()}
**ì„¤ëª…**: {rec.description}

**ê¶Œì¥ ì¡°ì¹˜**:
"""
                for action in rec.actions:
                    report += f"- {action}\n"
                
                report += f"""
**ì˜ˆìƒ ë¹„ìš©**: {rec.estimated_cost}
**íƒ€ì„ë¼ì¸**: {rec.timeline}
---
"""
        
        return report


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    monitor = ScalingMonitor()
    
    # ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ì €ì¥
    monitor.save_metrics_history()
    
    # í™•ì¥ ì œì•ˆ ì²´í¬
    metrics = monitor.get_system_metrics()
    recommendations = monitor.check_scaling_needs()
    
    # í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì „ì†¡ (ì œì•ˆì´ ìˆì„ ê²½ìš°)
    if recommendations:
        try:
            from telegram_notifier import send_scaling_alert
            send_scaling_alert(metrics, recommendations)
        except Exception as e:
            print(f"[ScalingMonitor] í…”ë ˆê·¸ë¨ ì•Œë¦¼ ì‹¤íŒ¨: {e}")
    
    # ë³´ê³ ì„œ ìƒì„±
    report = monitor.generate_report()
    print(report)
    
    # íŒŒì¼ë¡œ ì €ì¥
    report_path = f"scaling_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nğŸ“„ ë³´ê³ ì„œ ì €ì¥: {report_path}")


if __name__ == "__main__":
    main()
