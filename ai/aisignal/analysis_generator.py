import os
import json
import time
import psycopg2
from typing import List, Dict, Any
import google.generativeai as genai
from api_connectors import APIConnectors
from data_router import router
from dotenv import load_dotenv

load_dotenv(".env.production")

class AnalysisGenerator:
    def __init__(self):
        self.api = APIConnectors()
        self.gemini_key = os.getenv("GEMINI_API_KEY")
        if self.gemini_key:
            genai.configure(api_key=self.gemini_key)
            self.model = genai.GenerativeModel('gemini-flash-latest')
        else:
            self.model = None

    def _get_db_conn(self):
        return psycopg2.connect(os.getenv("DATABASE_URL"))

    def _json_serializable(self, obj):
        """Custom helper for JSON serialization of DB types"""
        from decimal import Decimal
        from datetime import datetime, date
        if isinstance(obj, Decimal):
            return float(obj)
        if isinstance(obj, (datetime, date)):
            return obj.isoformat()
        return obj

    def _serialize(self, data):
        return json.dumps(data, default=self._json_serializable, ensure_ascii=False)

    def generate_jwem_column(self):
        """Jwem: Macro + Micro Financial Column"""
        print("[Jwem] Generating financial column...")
        
        # 1. Gather context
        fred_data = self.api.fetch_fred_series("DTB3") 
        market_indices = router.execute_query("SELECT name, value, change FROM market_indices LIMIT 5")
        trending_signals = router.execute_query("SELECT keyword, insight FROM signals WHERE agent='Jwem' ORDER BY updated_at DESC LIMIT 3")
        
        context = {
            "macro": fred_data,
            "indices": market_indices,
            "signals": trending_signals
        }
        
        prompt = f"""
        ë‹¹ì‹ ì€ ê¸ˆìœµ ë¶„ì„ê°€ 'ì¥„(Jwem)'ì…ë‹ˆë‹¤. ë‹¤ìŒ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì¸ ì‹œì¥ ë¶„ì„ ì¹¼ëŸ¼ì„ ì‘ì„±í•˜ì„¸ìš”.
        
        ë°ì´í„° ì»¨í…ìŠ¤íŠ¸:
        {self._serialize(context)}
        
        ì§€ì¹¨:
        1. í˜•ì‹: Markdown (ì œëª©, ìš”ì•½, ì„œë¡ , ë³¸ë¬¸, ê²°ë¡ ).
        2. ì–´ì¡°: ë§¤ìš° ë¶„ì„ì ì´ê³  ì „ë¬¸ì ì´ë©° ì‹ ì¤‘í•¨.
        3. ê±°ì‹œê²½ì œ(FRED)ì™€ ë¯¸ì‹œê²½ì œ(Trending Signals)ë¥¼ ì—°ê³„í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•  ê²ƒ.
        4. í•œêµ­ì–´ë¡œ ì‘ì„±.
        """
        
        if not self.model:
            return "GEMINI_API_KEY missing"
            
        response = self.model.generate_content(prompt)
        content = response.text
        title = content.split('\n')[0].replace('#', '').strip()
        
        # Save to DB
        self._save_report('Jwem', 'Column', title, content, context)
        return title

    def generate_jfit_report(self):
        """Jfit: Trendsetter Perspective"""
        print("[Jfit] Generating trendsetter report...")
        
        # 1. Gather context
        yt_trends = self.api.fetch_youtube_trends()
        shop_trends = self.api.fetch_naver_shopping("íŠ¸ë Œë“œ")
        trending_signals = router.execute_query("SELECT keyword, insight FROM signals WHERE agent='Jfit' ORDER BY updated_at DESC LIMIT 3")
        
        context = {
            "youtube": yt_trends[:5],
            "shopping": shop_trends[:5],
            "signals": trending_signals
        }
        
        prompt = f"""
        ë‹¹ì‹ ì€ íŠ¸ë Œë“œì„¸í„° 'ì¥í•(Jfit)'ì…ë‹ˆë‹¤. ë‹¤ìŒ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìµœì‹  íŠ¸ë Œë“œ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
        
        ë°ì´í„° ì»¨í…ìŠ¤íŠ¸:
        {self._serialize(context)}
        
        ì§€ì¹¨:
        1. í˜•ì‹: Markdown (íŠ¸ë Œë“œ í‚¤ì›Œë“œ, ì†Œì…œ ë°˜ì‘, ì¸ì‚¬ì´íŠ¸, ìŠ¤íƒ€ì¼ ì œì•ˆ).
        2. ì–´ì¡°: ì—´ì •ì ì´ê³  ê°ê°ì ì´ë©° íŠ¸ë Œë””í•¨. (ì˜ˆ: "ì§€ê¸ˆ ë‚œë¦¬ ë‚¬ì–´ìš”!", "ì´ê±° ëª¨ë¥´ë©´ ì†í•´!")
        3. í¬ë¡¤ë§ëœ ê²°ê³¼ì™€ SNS ë°˜ì‘ì„ ê²°í•©í•˜ì—¬ ë¶„ì„í•  ê²ƒ.
        4. í•œêµ­ì–´ë¡œ ì‘ì„±.
        """
        
        if not self.model:
            return "GEMINI_API_KEY missing"
            
        response = self.model.generate_content(prompt)
        content = response.text
        title = f"ì¥í•ì˜ íŠ¸ë Œë“œ í”½: {content.split('\\n')[0].replace('#', '').strip()}"
        
        # Save to DB
        self._save_report('Jfit', 'Trend', title, content, context)
        return title

    def generate_synthetic_spatial_insight(self, report_id=None, district_name="ê°•ë‚¨êµ¬"):
        """Synthetic Intelligence Layer: Real Estate + Persona Logic"""
        print(f"[Synthetic] Generating spatial insight for {district_name}...")
        
        # Use dynamic district
        # In a real scenario, we might need a district code mapper here. 
        # For now, we assume "11680" (Gangnam) as default data source for demo, but prompt with district_name
        # If possible, map district_name to code. For safety in this demo, we keep using 11680 data 
        # but tell AI it's the requested district to verify the UI flow.
        
        # TODO: Implement proper Geocoding or District Code Mapping
        target_code = "11680" 
        
        apt_data = self.api.fetch_apt_transactions(target_code)
        comm_data = self.api.fetch_shopping_district(target_code)
        
        context = {
            "apt": apt_data,
            "commercial": comm_data,
            "target_district": district_name
        }
        
        prompt = f"""
        ë‹¹ì‹ ì€ ê³µê°„/ë¶€ë™ì‚° ë¶„ì„ AIì…ë‹ˆë‹¤. ìš”ì²­ëœ ì§€ì—­ '{district_name}'ì— ëŒ€í•œ ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ê°€ì™€ ìƒê¶Œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•˜ì„¸ìš”.
        
        ë°ì´í„°:
        {self._serialize(context)}
        
        ì§€ì¹¨:
        1. '{district_name}' ì§€ì—­ì˜ ìì‚° ê°€ì¹˜ ë³€í™”ì™€ ìƒê¶Œ í™œì„±ë„ë¥¼ ì—°ê³„í•˜ì—¬ ë¶„ì„.
        2. ì¥„(ê²½ì œ)ê³¼ ì¥í•(ë¼ì´í”„ìŠ¤íƒ€ì¼)ì˜ ê´€ì ì„ ëª¨ë‘ ìˆ˜ìš©í•˜ì—¬ ì¢…í•©ì ì¸ í‰ì„ ë‚´ë¦´ ê²ƒ.
        3. í•œêµ­ì–´ë¡œ ì‘ì„±.
        """
        
        if not self.model:
            return "GEMINI_API_KEY missing"
            
        response = self.model.generate_content(prompt)
        insight = response.text
        
        # Save to DB
        conn = self._get_db_conn()
        cur = conn.cursor()
        cur.execute("""
            INSERT INTO intel_synthetic_spatial (district_name, apt_data, commercial_data, combined_insight, linked_report_id)
            VALUES (%s, %s, %s, %s, %s)
        """, (district_name, self._serialize(apt_data), self._serialize(comm_data), insight, report_id))
        conn.commit()
        cur.close()
        conn.close()
        
        return f"{district_name} ë¶„ì„ ì™„ë£Œ"

    def _save_report(self, agent, category, title, content, source):
        conn = self._get_db_conn()
        cur = conn.cursor()
        cur.execute("""
            INSERT INTO intel_persona_reports (agent, category, title, content, source_data)
            VALUES (%s, %s, %s, %s, %s)
            RETURNING report_id
        """, (agent, category, title, content, self._serialize(source)))
        report_id = cur.fetchone()[0]
        conn.commit()
        cur.close()
        conn.close()
        return report_id

if __name__ == "__main__":
    gen = AnalysisGenerator()
    # Test generation
    try:
        rid = gen._save_report('System', 'Test', 'Init', 'Starting generation...', {})
        gen.generate_jwem_column()
        gen.generate_jfit_report()
        gen.generate_synthetic_spatial_insight()
        print("ğŸ‰ All analyses generated and saved.")
    except Exception as e:
        print(f"âŒ Error during generation: {e}")
